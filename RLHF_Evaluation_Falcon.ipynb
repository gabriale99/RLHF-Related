{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f308bb5-010d-44a9-93f8-a895bc7c78d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting textdistance\n",
      "  Downloading textdistance-4.6.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.23.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from evaluate)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk (from rouge_score)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.49-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyarrow>=12.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Collecting joblib (from nltk->rouge_score)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas->evaluate)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading textdistance-4.6.1-py3-none-any.whl (31 kB)\n",
      "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.9/407.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=67ad6c6248fd14dd105537631f06708768081bc4e3a5235f2c21f8b355f3254f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: xxhash, tzdata, textdistance, tenacity, safetensors, regex, pydantic-core, pyarrow-hotfix, pyarrow, packaging, orjson, mypy-extensions, multidict, jsonpatch, joblib, greenlet, frozenlist, dill, async-timeout, annotated-types, absl-py, yarl, typing-inspect, tiktoken, SQLAlchemy, responses, pydantic, pandas, nltk, multiprocess, marshmallow, huggingface-hub, aiosignal, tokenizers, rouge_score, openai, langsmith, dataclasses-json, bitsandbytes, aiohttp, accelerate, transformers, langchain-core, langchain-text-splitters, langchain-community, datasets, langchain, evaluate\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed SQLAlchemy-2.0.29 absl-py-2.1.0 accelerate-0.29.3 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 bitsandbytes-0.43.1 dataclasses-json-0.6.4 datasets-2.19.0 dill-0.3.8 evaluate-0.4.1 frozenlist-1.4.1 greenlet-3.0.3 huggingface-hub-0.22.2 joblib-1.4.0 jsonpatch-1.33 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.45 langchain-text-splitters-0.0.1 langsmith-0.1.49 marshmallow-3.21.1 multidict-6.0.5 multiprocess-0.70.16 mypy-extensions-1.0.0 nltk-3.8.1 openai-1.23.2 orjson-3.10.1 packaging-23.2 pandas-2.2.2 pyarrow-16.0.0 pyarrow-hotfix-0.6 pydantic-2.7.0 pydantic-core-2.18.1 regex-2024.4.16 responses-0.18.0 rouge_score-0.1.2 safetensors-0.4.3 tenacity-8.2.3 textdistance-4.6.1 tiktoken-0.6.0 tokenizers-0.19.1 transformers-4.40.0 typing-inspect-0.9.0 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers evaluate tqdm rouge_score textdistance langchain accelerate openai tiktoken bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57acb543-33b0-4777-ab56-d95e3228f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "from datasets import load_dataset\n",
    "from textdistance import jaro_winkler\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain.evaluation import EmbeddingDistance\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '<OPENAI API KEY>'\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9c3afa-b8f0-440e-8463-acea2f44ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FalconForCausalLM were not initialized from the model checkpoint at rlhf-falcon_test and are newly initialized: ['h.0.input_layernorm.bias', 'h.0.input_layernorm.weight', 'h.0.mlp.dense_4h_to_h.weight', 'h.0.mlp.dense_h_to_4h.weight', 'h.0.self_attention.dense.weight', 'h.0.self_attention.query_key_value.weight', 'h.1.input_layernorm.bias', 'h.1.input_layernorm.weight', 'h.1.mlp.dense_4h_to_h.weight', 'h.1.mlp.dense_h_to_4h.weight', 'h.1.self_attention.dense.weight', 'h.1.self_attention.query_key_value.weight', 'h.10.input_layernorm.bias', 'h.10.input_layernorm.weight', 'h.10.mlp.dense_4h_to_h.weight', 'h.10.mlp.dense_h_to_4h.weight', 'h.10.self_attention.dense.weight', 'h.10.self_attention.query_key_value.weight', 'h.11.input_layernorm.bias', 'h.11.input_layernorm.weight', 'h.11.mlp.dense_4h_to_h.weight', 'h.11.mlp.dense_h_to_4h.weight', 'h.11.self_attention.dense.weight', 'h.11.self_attention.query_key_value.weight', 'h.12.input_layernorm.bias', 'h.12.input_layernorm.weight', 'h.12.mlp.dense_4h_to_h.weight', 'h.12.mlp.dense_h_to_4h.weight', 'h.12.self_attention.dense.weight', 'h.12.self_attention.query_key_value.weight', 'h.13.input_layernorm.bias', 'h.13.input_layernorm.weight', 'h.13.mlp.dense_4h_to_h.weight', 'h.13.mlp.dense_h_to_4h.weight', 'h.13.self_attention.dense.weight', 'h.13.self_attention.query_key_value.weight', 'h.14.input_layernorm.bias', 'h.14.input_layernorm.weight', 'h.14.mlp.dense_4h_to_h.weight', 'h.14.mlp.dense_h_to_4h.weight', 'h.14.self_attention.dense.weight', 'h.14.self_attention.query_key_value.weight', 'h.15.input_layernorm.bias', 'h.15.input_layernorm.weight', 'h.15.mlp.dense_4h_to_h.weight', 'h.15.mlp.dense_h_to_4h.weight', 'h.15.self_attention.dense.weight', 'h.15.self_attention.query_key_value.weight', 'h.16.input_layernorm.bias', 'h.16.input_layernorm.weight', 'h.16.mlp.dense_4h_to_h.weight', 'h.16.mlp.dense_h_to_4h.weight', 'h.16.self_attention.dense.weight', 'h.16.self_attention.query_key_value.weight', 'h.17.input_layernorm.bias', 'h.17.input_layernorm.weight', 'h.17.mlp.dense_4h_to_h.weight', 'h.17.mlp.dense_h_to_4h.weight', 'h.17.self_attention.dense.weight', 'h.17.self_attention.query_key_value.weight', 'h.18.input_layernorm.bias', 'h.18.input_layernorm.weight', 'h.18.mlp.dense_4h_to_h.weight', 'h.18.mlp.dense_h_to_4h.weight', 'h.18.self_attention.dense.weight', 'h.18.self_attention.query_key_value.weight', 'h.19.input_layernorm.bias', 'h.19.input_layernorm.weight', 'h.19.mlp.dense_4h_to_h.weight', 'h.19.mlp.dense_h_to_4h.weight', 'h.19.self_attention.dense.weight', 'h.19.self_attention.query_key_value.weight', 'h.2.input_layernorm.bias', 'h.2.input_layernorm.weight', 'h.2.mlp.dense_4h_to_h.weight', 'h.2.mlp.dense_h_to_4h.weight', 'h.2.self_attention.dense.weight', 'h.2.self_attention.query_key_value.weight', 'h.20.input_layernorm.bias', 'h.20.input_layernorm.weight', 'h.20.mlp.dense_4h_to_h.weight', 'h.20.mlp.dense_h_to_4h.weight', 'h.20.self_attention.dense.weight', 'h.20.self_attention.query_key_value.weight', 'h.21.input_layernorm.bias', 'h.21.input_layernorm.weight', 'h.21.mlp.dense_4h_to_h.weight', 'h.21.mlp.dense_h_to_4h.weight', 'h.21.self_attention.dense.weight', 'h.21.self_attention.query_key_value.weight', 'h.22.input_layernorm.bias', 'h.22.input_layernorm.weight', 'h.22.mlp.dense_4h_to_h.weight', 'h.22.mlp.dense_h_to_4h.weight', 'h.22.self_attention.dense.weight', 'h.22.self_attention.query_key_value.weight', 'h.23.input_layernorm.bias', 'h.23.input_layernorm.weight', 'h.23.mlp.dense_4h_to_h.weight', 'h.23.mlp.dense_h_to_4h.weight', 'h.23.self_attention.dense.weight', 'h.23.self_attention.query_key_value.weight', 'h.24.input_layernorm.bias', 'h.24.input_layernorm.weight', 'h.24.mlp.dense_4h_to_h.weight', 'h.24.mlp.dense_h_to_4h.weight', 'h.24.self_attention.dense.weight', 'h.24.self_attention.query_key_value.weight', 'h.25.input_layernorm.bias', 'h.25.input_layernorm.weight', 'h.25.mlp.dense_4h_to_h.weight', 'h.25.mlp.dense_h_to_4h.weight', 'h.25.self_attention.dense.weight', 'h.25.self_attention.query_key_value.weight', 'h.26.input_layernorm.bias', 'h.26.input_layernorm.weight', 'h.26.mlp.dense_4h_to_h.weight', 'h.26.mlp.dense_h_to_4h.weight', 'h.26.self_attention.dense.weight', 'h.26.self_attention.query_key_value.weight', 'h.27.input_layernorm.bias', 'h.27.input_layernorm.weight', 'h.27.mlp.dense_4h_to_h.weight', 'h.27.mlp.dense_h_to_4h.weight', 'h.27.self_attention.dense.weight', 'h.27.self_attention.query_key_value.weight', 'h.28.input_layernorm.bias', 'h.28.input_layernorm.weight', 'h.28.mlp.dense_4h_to_h.weight', 'h.28.mlp.dense_h_to_4h.weight', 'h.28.self_attention.dense.weight', 'h.28.self_attention.query_key_value.weight', 'h.29.input_layernorm.bias', 'h.29.input_layernorm.weight', 'h.29.mlp.dense_4h_to_h.weight', 'h.29.mlp.dense_h_to_4h.weight', 'h.29.self_attention.dense.weight', 'h.29.self_attention.query_key_value.weight', 'h.3.input_layernorm.bias', 'h.3.input_layernorm.weight', 'h.3.mlp.dense_4h_to_h.weight', 'h.3.mlp.dense_h_to_4h.weight', 'h.3.self_attention.dense.weight', 'h.3.self_attention.query_key_value.weight', 'h.30.input_layernorm.bias', 'h.30.input_layernorm.weight', 'h.30.mlp.dense_4h_to_h.weight', 'h.30.mlp.dense_h_to_4h.weight', 'h.30.self_attention.dense.weight', 'h.30.self_attention.query_key_value.weight', 'h.31.input_layernorm.bias', 'h.31.input_layernorm.weight', 'h.31.mlp.dense_4h_to_h.weight', 'h.31.mlp.dense_h_to_4h.weight', 'h.31.self_attention.dense.weight', 'h.31.self_attention.query_key_value.weight', 'h.4.input_layernorm.bias', 'h.4.input_layernorm.weight', 'h.4.mlp.dense_4h_to_h.weight', 'h.4.mlp.dense_h_to_4h.weight', 'h.4.self_attention.dense.weight', 'h.4.self_attention.query_key_value.weight', 'h.5.input_layernorm.bias', 'h.5.input_layernorm.weight', 'h.5.mlp.dense_4h_to_h.weight', 'h.5.mlp.dense_h_to_4h.weight', 'h.5.self_attention.dense.weight', 'h.5.self_attention.query_key_value.weight', 'h.6.input_layernorm.bias', 'h.6.input_layernorm.weight', 'h.6.mlp.dense_4h_to_h.weight', 'h.6.mlp.dense_h_to_4h.weight', 'h.6.self_attention.dense.weight', 'h.6.self_attention.query_key_value.weight', 'h.7.input_layernorm.bias', 'h.7.input_layernorm.weight', 'h.7.mlp.dense_4h_to_h.weight', 'h.7.mlp.dense_h_to_4h.weight', 'h.7.self_attention.dense.weight', 'h.7.self_attention.query_key_value.weight', 'h.8.input_layernorm.bias', 'h.8.input_layernorm.weight', 'h.8.mlp.dense_4h_to_h.weight', 'h.8.mlp.dense_h_to_4h.weight', 'h.8.self_attention.dense.weight', 'h.8.self_attention.query_key_value.weight', 'h.9.input_layernorm.bias', 'h.9.input_layernorm.weight', 'h.9.mlp.dense_4h_to_h.weight', 'h.9.mlp.dense_h_to_4h.weight', 'h.9.self_attention.dense.weight', 'h.9.self_attention.query_key_value.weight', 'lm_head.weight', 'ln_f.bias', 'ln_f.weight', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f19d28187944eda167adeb4f5f67ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900dd947740748ac85261036c8a0a096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2823224194e4b3a952ac434162856f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specify device type to use to run LLMs\n",
    "device_type = \"cuda:0\"\n",
    "\n",
    "# load fine-tuned model and tokenizer\n",
    "base_model_name = \"vilsonrodrigues/falcon-7b-sharded\"\n",
    "# model_name = \"rlhf-falcon_v3\"\n",
    "model_name = \"rlhf-falcon_test\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "trained_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_type,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name ,trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"right\"  # set padding to the right to avoid issues with fp16 (when using 4-bit quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbaf4cf-0d39-41a9-a0bf-62cdf1db579d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156382cbc1f44929ba3421ff0a9150f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question'],\n",
       "        num_rows: 24546\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_files = {'test':'test_augment_data.json'}\n",
    "data_files = {'test':'val_augment_data.json'}\n",
    "\n",
    "data = load_dataset(\"json\", data_files=data_files)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5130af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge4(pred, ref):\n",
    "    '''\n",
    "    Purpose: to calculate ROUGE-4 score for a single data point\n",
    "    @params pred: a list of predictions made by model (str)\n",
    "    @params ref: a list of references/actual answers (str)\n",
    "    returns: a dict of evaluation results (dict)\n",
    "    '''\n",
    "    # get rouge-4 score; since not included in evaluate load method\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge4'], use_stemmer=True)\n",
    "    scores = scorer.score(pred, ref)\n",
    "\n",
    "    res = scores['rouge4'][2]  # get fmeasure (precision+recall) results\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5107bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_bleu(preds, refs):\n",
    "    '''\n",
    "    Purpose: to calculate ROUGE & BLEU metrics for a set of data samples\n",
    "    @params preds: a list of predictions made by model (list of str)\n",
    "    @params refs: a list of references/actual answers (list of str)\n",
    "    returns: a dict of evaluation results (dict)\n",
    "    '''\n",
    "\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "    rouge_res = rouge_metric.compute(predictions=preds, references=refs, use_stemmer=True)\n",
    "\n",
    "    # calculate average rouge-4 score\n",
    "    rouge4_res = []\n",
    "    for i in range(len(preds)):\n",
    "        pred = preds[i]\n",
    "        ref = refs[i]\n",
    "        r4 = calculate_rouge4(pred, ref)\n",
    "        rouge4_res.append(r4)\n",
    "\n",
    "    r4_avg = np.mean(rouge4_res)\n",
    "\n",
    "    # put all results together\n",
    "    res = rouge_res\n",
    "    rouge_res['rouge4'] = r4_avg\n",
    "\n",
    "    # calculate bleu scores\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    bleu_res = bleu_metric.compute(predictions=preds, references=refs)\n",
    "\n",
    "    for i in range(len(bleu_res['precisions'])):\n",
    "        name_ix = i+1\n",
    "\n",
    "        k = f'bleu{name_ix}'\n",
    "        res[k] = bleu_res['precisions'][i]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9899e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to format data to prompt instruction format\n",
    "def get_model_response(model, question):\n",
    "    '''\n",
    "    Purpose: to generate an answer from model for a given question\n",
    "    @params model: the loaded LLM model\n",
    "    @params question: a question for model to answer (str)\n",
    "    returns: an answer (str)\n",
    "    '''\n",
    "    tokens = tokenizer(question, return_tensors=\"pt\")\n",
    "    input_ids = tokens.input_ids.to(device_type)\n",
    "    attention_mask = tokens.attention_mask.to(device_type)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=512, no_repeat_ngram_size=2, max_time=7, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185691c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [9:45:23<00:00,  7.02s/it]\n"
     ]
    }
   ],
   "source": [
    "questions = data['test']['question'][:5000]\n",
    "refs = data['test']['answer']  # actual answer\n",
    "\n",
    "# get model predictions\n",
    "preds = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    q = questions[i]\n",
    "    ans = get_model_response(trained_model, q)\n",
    "    preds.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "698208c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'rlhf_falcon_val_set_preds_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(preds, f, ensure_ascii=False, indent=4)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2ec0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089b181e997b43ac8bbef78d0d0e2954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8369c971b53b47c2a5db5158046f8fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a37630c1f2b457b9a919526e2494d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ac896be737493e8e0a802a128f061e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      " Results: \n",
      " {'rouge1': 0.07300136394829512, 'rouge2': 0.030422385925886426, 'rougeL': 0.055352078611822855, 'rougeLsum': 0.055357851885465985, 'rouge4': 0.00962228533999513, 'bleu1': 0.042021178650657486, 'bleu2': 0.016342447966505417, 'bleu3': 0.008827271999216936, 'bleu4': 0.005017377038402807}\n"
     ]
    }
   ],
   "source": [
    "# calculate rouge & bleu metrics\n",
    "refs = data['test']['answer']\n",
    "n = 5000  # data size to calculate metrics\n",
    "eval_results = calculate_rouge_bleu(preds[:n], refs[:n])\n",
    "\n",
    "print(f'----------\\n Results: \\n {eval_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e9e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average jaro-winkler distance is: 0.5733590816562064\n"
     ]
    }
   ],
   "source": [
    "# calculate jaro-winkler distance\n",
    "refs = data['test']['answer']\n",
    "n = 5000 # data size to calculate metrics\n",
    "\n",
    "jaros = []\n",
    "for i in range(n):\n",
    "    pred = preds[i]\n",
    "    ref = refs[i]\n",
    "    distance = jaro_winkler(pred, ref)\n",
    "    jaros.append(distance)\n",
    "\n",
    "print(f'The average jaro-winkler distance is: {np.mean(jaros)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ddbe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "evaluator = load_evaluator(\"embedding_distance\", distance_metric=EmbeddingDistance.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad3b6d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 5000/5000 [18:48<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cosine embedding distance is: 0.1672721869285779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate cosine embedding distance\n",
    "refs = data['test']['answer']\n",
    "n = 5000 # data size to calculate metrics\n",
    "\n",
    "cos_dist = []\n",
    "for i in tqdm(range(n)):\n",
    "    pred = preds[i]\n",
    "    ref = refs[i]\n",
    "    distance = evaluator.evaluate_strings(prediction=pred, reference=ref)\n",
    "    cos_dist.append(distance['score'])\n",
    "\n",
    "print(f'The average cosine embedding distance is: {np.mean(cos_dist)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
